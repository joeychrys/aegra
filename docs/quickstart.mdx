---
title: "Quickstart"
description: "Get a running Aegra server in under 5 minutes."
---

## Prerequisites

- Python 3.12+
- Docker (for PostgreSQL)

## Create a project

<Steps>
  <Step title="Install the CLI">
    ```bash
    pip install aegra-cli
    ```
  </Step>
  <Step title="Initialize a new project">
    ```bash
    aegra init
    ```

    The CLI will prompt you for a location, template, and project name. Choose the **simple-chatbot** template to get started quickly.
  </Step>
  <Step title="Configure your environment">
    ```bash
    cd <your-project>
    cp .env.example .env
    ```

    Open `.env` and add your `OPENAI_API_KEY`.
  </Step>
  <Step title="Install dependencies and start the server">
    The generated project uses [uv](https://docs.astral.sh/uv/) for dependency management. The `pyproject.toml` created by `aegra init` defines your project's dependencies, and `uv` handles the rest.

    ```bash
    uv sync
    uv run aegra dev
    ```

    This starts a PostgreSQL container, applies database migrations, and launches the server with hot reload.
  </Step>
</Steps>

Your server is running at [http://localhost:8000](http://localhost:8000). Visit [http://localhost:8000/docs](http://localhost:8000/docs) to explore the API.

<Note>
  Always install `aegra-cli` directly â€” not the `aegra` meta-package. The `aegra` package on PyPI is a convenience wrapper that does not support version pinning.
</Note>

## Talk to your agent

Your LangGraph code works without changes:

```python
import asyncio
from langgraph_sdk import get_client


async def main():
    client = get_client(url="http://localhost:8000")

    # Each graph in aegra.json gets a default assistant with the same ID
    thread = await client.threads.create()

    async for chunk in client.runs.stream(
        thread_id=thread["thread_id"],
        assistant_id="agent",
        input={"messages": [{"type": "human", "content": "Hello!"}]},
    ):
        print(chunk)


asyncio.run(main())
```

## Connect a frontend

Aegra implements the [Agent Protocol](https://github.com/langchain-ai/agent-protocol), so it works with any compatible frontend:

<CardGroup cols={3}>
  <Card title="Agent Chat UI" icon="comments" href="https://github.com/langchain-ai/agent-chat-ui">
    Open-source chat interface for agent interactions.
  </Card>
  <Card title="LangGraph Studio" icon="desktop" href="https://github.com/langchain-ai/langgraph-studio">
    Visual graph debugger and testing tool.
  </Card>
  <Card title="CopilotKit" icon="wand-magic-sparkles" href="https://github.com/CopilotKit/CopilotKit">
    In-app AI copilot framework via AG-UI protocol.
  </Card>
</CardGroup>

## What's next

<CardGroup cols={2}>
  <Card title="Build your first agent" icon="rocket" href="/getting-started">
    Hands-on tutorial: build, deploy, and interact with an agent step by step.
  </Card>
  <Card title="Streaming" icon="signal-stream" href="/guides/streaming">
    Understand stream modes, SSE events, and reconnection.
  </Card>
  <Card title="Authentication" icon="lock" href="/guides/authentication">
    Add JWT, OAuth, or Firebase auth to your server.
  </Card>
  <Card title="Deployment" icon="cloud" href="/guides/deployment">
    Deploy to Docker, PaaS, or Kubernetes.
  </Card>
</CardGroup>
